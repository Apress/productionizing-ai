{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://www.earthdatascience.org/courses/use-data-open-source-python/intro-to-apis/twitter-data-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE OFF INSTALL\n",
    "# %pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries and Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "\n",
    "import credentials # Import api/access_token keys from credentials.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tw.OAuthHandler(credentials.API_KEY, credentials.API_SECRET_KEY)\n",
    "auth.set_access_token(credentials.ACCESS_TOKEN, credentials.ACCESS_TOKEN_SECRET)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search Twitter for Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search term and the date_since date as variables\n",
    "search_words = \"#uefa\"\n",
    "date_since = \"2020-02-16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect tweets\n",
    "tweets = tw.Cursor(api.search,\n",
    "                       q=search_words,\n",
    "                       lang=\"en\",\n",
    "                       since=date_since).items(5)\n",
    "\n",
    "# Collect a list of tweets\n",
    "[tweet.text for tweet in tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_search = search_words + \" -filter:retweets\"\n",
    "new_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tw.Cursor(api.search,\n",
    "                       q=new_search,\n",
    "                       lang=\"en\",\n",
    "                       since=date_since).items(5)\n",
    "\n",
    "[tweet.text for tweet in tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Who is tweeting ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tw.Cursor(api.search, \n",
    "                           q=new_search,\n",
    "                           lang=\"en\",\n",
    "                           since=date_since).items(5)\n",
    "\n",
    "users_locs = [[tweet.user.screen_name, tweet.user.location] for tweet in tweets]\n",
    "users_locs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Pandas Dataframe From A List of Tweet Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_text = pd.DataFrame(data=users_locs, \n",
    "                    columns=['user', \"location\"])\n",
    "tweet_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Customizing Twitter Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise -\n",
    "\n",
    "extract 1000 tweets on climate change and filter out retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_search = \"climate+change -filter:retweets\"\n",
    "\n",
    "tweets = tw.Cursor(api.search,\n",
    "                   q=new_search,\n",
    "                   lang=\"en\",\n",
    "                   since='2021-02-16').items(1000)\n",
    "\n",
    "all_tweets = [tweet.text for tweet in tweets]\n",
    "all_tweets[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise -\n",
    "\n",
    "extract last 5 tweets by Christiano Ronaldo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "screen_name = \"@Cristiano\"\n",
    "\n",
    "tweets = api.user_timeline(screen_name = screen_name,count=10)\n",
    "\n",
    "all_tweets = [tweet.text for tweet in tweets]\n",
    "all_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise - get as much info as possible about coronavirus and export it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference:\n",
    "\n",
    "# https://towardsdatascience.com/how-to-scrape-more-information-from-tweets-on-twitter-44fd540b8a1f\n",
    "    \n",
    "text_query = 'Coronavirus'\n",
    "max_tweets = 150\n",
    " \n",
    "# Creation of query method using parameters\n",
    "tweets = tw.Cursor(api.search,q=text_query).items(max_tweets)\n",
    " \n",
    "# Pulling information from tweets iterable object\n",
    "# Add or remove tweet information you want in the below list comprehension\n",
    "tweets_list = [[tweet.text, tweet.created_at, tweet.id_str, tweet.user.name, tweet.user.screen_name, \n",
    "                tweet.user.id_str, tweet.user.location, tweet.user.url, tweet.user.description, \n",
    "                tweet.user.verified, tweet.user.followers_count, tweet.user.friends_count, \n",
    "                tweet.user.favourites_count, tweet.user.statuses_count, tweet.user.listed_count, \n",
    "                tweet.user.created_at, tweet.user.profile_image_url_https, tweet.user.default_profile,\n",
    "                tweet.user.default_profile_image] for tweet in tweets]\n",
    " \n",
    "# Creation of dataframe from tweets_list\n",
    "# Did not include column names to simplify code \n",
    "tweets_df = pd.DataFrame(tweets_list)\n",
    "tweets_df.to_csv(\"covid_export.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.head() # quick check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further references"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.earthdatascience.org/courses/use-data-open-source-python/intro-to-apis/calculate-tweet-word-frequencies-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise -\n",
    "\n",
    "# Set up a user prompt for a twitter hashtag, including no. of tweets to analyse, \n",
    "# return a breakdown of tweet polarity (+ve, -ve and neutral sentiment)\n",
    "# and then plot a pie chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = input(\"Please enter keyword or hashtag to search: \")\n",
    "noOfTweet = int(input (\"Please enter how many tweets to analyze: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tw.Cursor(api.search, q=keyword).items(noOfTweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob # API for NLP https://textblob.readthedocs.io/en/dev/\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# initialisation\n",
    "tweet_list = []\n",
    "positive = 0\n",
    "negative = 0\n",
    "neutral = 0\n",
    "polarity = 0\n",
    "polarity = 0\n",
    "\n",
    "#loop thru tweets\n",
    "for tweet in tweets:\n",
    "    #print(tweet.text)\n",
    "    tweet_list.append(tweet.text)\n",
    "    analysis = TextBlob(tweet.text)\n",
    "    score = SentimentIntensityAnalyzer().polarity_scores(tweet.text)\n",
    "    comp = score['compound']\n",
    "    polarity += analysis.sentiment.polarity\n",
    "    \n",
    "    # keep running total of sentiment of tweets (+ve, -ve, neutral)\n",
    "    if score['neg'] > score['pos']:\n",
    "        negative += 1\n",
    "    elif score['pos'] > score['neg']:\n",
    "        positive += 1\n",
    "    elif score['pos'] == score['neg']:\n",
    "        neutral += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pie chart\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = ['Positive ['+str(positive)+'%]' , 'Neutral ['+str(neutral)+'%]','Negative ['+str(negative)+'%]']\n",
    "sizes = [positive, neutral, negative]\n",
    "colors = ['green', 'blue','red']\n",
    "patches, texts = plt.pie(sizes,colors=colors, startangle=90)\n",
    "plt.style.use('default')\n",
    "plt.legend(labels)\n",
    "plt.title(\"Sentiment Analysis Result for keyword= \"+keyword+\"\" )\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
