{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting Customer Churn"
      ],
      "metadata": {
        "id": "VsrmDjW55POn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://d35fo82fjcw0y8.cloudfront.net/2017/09/26225705/header%402x.png\" alt=\"CleverTap\" width = 400/>"
      ],
      "metadata": {
        "id": "2MIYOiuk4xYD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image Source: https://clevertap.com/blog/churn-rate/"
      ],
      "metadata": {
        "id": "0htsoPTD5H4j"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPyyW6JgCi1j"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBpoeJLCCi1j"
      },
      "source": [
        "### Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4NOmeuVCi1j"
      },
      "outputs": [],
      "source": [
        "# standard libraries for data analysis\n",
        "    \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from scipy.stats import norm, skew\n",
        "from scipy import stats\n",
        "import statsmodels.api as sm\n",
        "\n",
        "\n",
        "# preprocessing modules\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler \n",
        "\n",
        "\n",
        "# model selection\n",
        "\n",
        "from sklearn import svm, tree, linear_model, neighbors\n",
        "from sklearn import naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "# model performance\n",
        "    \n",
        "from sklearn.metrics import confusion_matrix, accuracy_score \n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, fbeta_score\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "from sklearn import feature_selection\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "\n",
        "from sklearn.metrics import classification_report, precision_recall_curve\n",
        "from sklearn.metrics import auc, roc_auc_score, roc_curve\n",
        "from sklearn.metrics import make_scorer, recall_score, log_loss\n",
        "from sklearn.metrics import average_precision_score\n",
        "  \n",
        "\n",
        "# data visualization\n",
        "\n",
        "import seaborn as sn\n",
        "from matplotlib import pyplot\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pylab as pylab\n",
        "import matplotlib \n",
        "\n",
        "%matplotlib inline\n",
        "color = sn.color_palette()\n",
        "import matplotlib.ticker as mtick\n",
        "from IPython.display import display\n",
        "pd.options.display.max_columns = None\n",
        "from pandas.plotting import scatter_matrix\n",
        "\n",
        "# utility libraries\n",
        "    \n",
        "import random\n",
        "import os\n",
        "import re\n",
        "import sys\n",
        "import timeit\n",
        "import string\n",
        "import time\n",
        "from datetime import datetime\n",
        "from time import time\n",
        "from dateutil.parser import parse\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Q4jb5frCi1l"
      },
      "source": [
        "### Data Import and EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2ob-6ZHCi1m"
      },
      "outputs": [],
      "source": [
        "# NB drag and drop csv in main Colab temp folder (click folder on RHS and drag and drop)\n",
        "dataset = pd.read_csv('customer_churn_data.csv') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiOp7s85Ci1m"
      },
      "outputs": [],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.shape"
      ],
      "metadata": {
        "id": "g_3WTAqA6UO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBrfugW0Ci1m"
      },
      "outputs": [],
      "source": [
        "dataset.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nw1iRDC0Ci1m"
      },
      "outputs": [],
      "source": [
        "dataset.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fpWjaznCi1n"
      },
      "outputs": [],
      "source": [
        "dataset.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NB TotalCharges shown as object but this is a cost, so should be float - we will check this later"
      ],
      "metadata": {
        "id": "iqMG1ZW0GrNQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6NHW393LCi1n"
      },
      "outputs": [],
      "source": [
        "dataset.isna().sum() # missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "no missing values in this case"
      ],
      "metadata": {
        "id": "MNLOR661GAFE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sd2uQRlkCi1o"
      },
      "outputs": [],
      "source": [
        "# quick point check - unique values in each categorical variable:\n",
        "\n",
        "dataset[\"PaymentMethod\"].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCXwAuoECi1o"
      },
      "outputs": [],
      "source": [
        "dataset[\"PaymentMethod\"].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7DjTj5NCi1o"
      },
      "source": [
        "### Target variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fpt7DBU9Ci1o"
      },
      "outputs": [],
      "source": [
        "dataset[\"Churn\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "note imbalanced target variable"
      ],
      "metadata": {
        "id": "Uo6q2faCFppY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAWku8txCi1p"
      },
      "source": [
        "### Wrangling"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we noted earlier TotalCharges is read as an object but should be numeric - lets:\n",
        "\n",
        "a) count the number of \"errors\"\n",
        "\n",
        "b) coerce the \"error\" values in the column as NAs \n",
        "\n",
        "c) then change data type to float\n",
        "\n",
        "d) check the distribution of the column\n",
        "\n",
        "e) replace with an appropriate proxy"
      ],
      "metadata": {
        "id": "w6G-DpxPKDiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.to_numeric(dataset['TotalCharges'],errors='coerce').isna().sum()"
      ],
      "metadata": {
        "id": "Y1X7ULngJoXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we have 11 "
      ],
      "metadata": {
        "id": "qnrUN8nZKfOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['TotalCharges'] = pd.to_numeric(dataset['TotalCharges'],errors='coerce')"
      ],
      "metadata": {
        "id": "e1lQ86AlKqkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSG_kimXCi1p"
      },
      "outputs": [],
      "source": [
        "dataset['TotalCharges'] = dataset['TotalCharges'].astype(\"float\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['TotalCharges'].hist()"
      ],
      "metadata": {
        "id": "apguPyXWLe9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# skewed, so replace NAs with median\n",
        "dataset['TotalCharges'] =  dataset['TotalCharges'].fillna(dataset['TotalCharges'].median()).round(0)"
      ],
      "metadata": {
        "id": "hYpkWMWGMrqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# final check missing values gone\n",
        "dataset['TotalCharges'].isna().sum()"
      ],
      "metadata": {
        "id": "zuWkjvUOM_Ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "metadata": {
        "id": "t9ixw_xbPV5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cpJ2azQCi1q"
      },
      "source": [
        "### Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vo4n6FSUCi1q"
      },
      "outputs": [],
      "source": [
        "# create a label encoder object\n",
        "le = LabelEncoder()\n",
        "\n",
        "# label encoding will be used for columns with 2 or less unique values\n",
        "le_count = 0\n",
        "for col in dataset.columns[1:]:\n",
        "    if dataset[col].dtype == 'object':\n",
        "        if len(list(dataset[col].unique())) <= 2:\n",
        "            le.fit(dataset[col])\n",
        "            dataset[col] = le.transform(dataset[col])\n",
        "            le_count += 1\n",
        "print('{} columns were label encoded.'.format(le_count))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIOrcmxxCi1q"
      },
      "source": [
        "## Visual EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### \"Binary\"-type variables"
      ],
      "metadata": {
        "id": "tTspJg-A-JLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_binary = dataset[['gender', 'SeniorCitizen', 'Partner', 'Dependents','PhoneService', 'PaperlessBilling']]\n",
        "dataset_binary.hist(figsize=(10,10))"
      ],
      "metadata": {
        "id": "b6V-9BE668bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Continuous-type variables"
      ],
      "metadata": {
        "id": "5-9qjMXq-ECD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_cont = dataset[['tenure', 'MonthlyCharges', 'TotalCharges']]\n",
        "dataset_cont.hist(figsize=(10,10))"
      ],
      "metadata": {
        "id": "_QfjU-nb7rPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Categorical variables"
      ],
      "metadata": {
        "id": "_0Q8NySu9-lr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qin6YrJRCi1u"
      },
      "outputs": [],
      "source": [
        "services = ['PhoneService','MultipleLines','InternetService','OnlineSecurity',\n",
        "           'OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']\n",
        "\n",
        "fig, axes = plt.subplots(nrows = 3,ncols = 3,figsize = (15,12))\n",
        "for i, item in enumerate(services):\n",
        "    if i < 3:\n",
        "        ax = dataset[item].value_counts().plot(kind = 'bar',ax=axes[i,0],rot = 0, color ='#f3babc' )\n",
        "        \n",
        "    elif i >=3 and i < 6:\n",
        "        ax = dataset[item].value_counts().plot(kind = 'bar',ax=axes[i-3,1],rot = 0,color ='#9b9c9a')\n",
        "        \n",
        "    elif i < 9:\n",
        "        ax = dataset[item].value_counts().plot(kind = 'bar',ax=axes[i-6,2],rot = 0,color = '#ec838a')\n",
        "    ax.set_title(item)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Point-checks"
      ],
      "metadata": {
        "id": "49pZMUax9kLu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dY_5MCp5Ci1r"
      },
      "source": [
        "lets also get a better view on contract type...."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qk_TQiMbCi1s"
      },
      "outputs": [],
      "source": [
        "\n",
        "contract_split = dataset[[ \"customerID\", \"Contract\"]]\n",
        "sectors = contract_split .groupby (\"Contract\")\n",
        "contract_split = pd.DataFrame(sectors[\"customerID\"].count())\n",
        "contract_split.rename(columns={'customerID':'No. of customers'}, inplace=True)\n",
        "\n",
        "\n",
        "ax =  contract_split[[\"No. of customers\"]].plot.bar(title = 'Customers by Contract Type', legend =True, table = False, grid = False,  subplots = False,  figsize =(12, 7), color ='#ec838a', fontsize = 15, stacked=False)\n",
        "\n",
        "plt.ylabel('No. of Customers\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
        "plt.xlabel('\\n Contract Type',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
        "plt.title('Customers by Contract Type \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"22\", fontfamily = \"sans-serif\")\n",
        "plt.legend(loc='upper right', fontsize = \"medium\")\n",
        "plt.xticks(rotation=0, horizontalalignment=\"center\")\n",
        "plt.yticks(rotation=0, horizontalalignment=\"right\")\n",
        "\n",
        "x_labels = np.array(contract_split[[\"No. of customers\"]])\n",
        "\n",
        "def add_value_labels(ax, spacing=5):   \n",
        "    for rect in ax.patches:      \n",
        "        y_value = rect.get_height()\n",
        "        x_value = rect.get_x() + rect.get_width() / 2       \n",
        "        space = spacing        \n",
        "        va = 'bottom'      \n",
        "        if y_value < 0:           \n",
        "            space *= -1            \n",
        "            va = 'top'       \n",
        "        label = \"{:.0f}\".format(y_value)      \n",
        "        ax.annotate(\n",
        "            label,                      \n",
        "            (x_value, y_value),         \n",
        "            xytext=(0, space),          \n",
        "            textcoords=\"offset points\", \n",
        "            ha='center',                \n",
        "            va=va)                                                             \n",
        "add_value_labels(ax)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urgILBetCi1t"
      },
      "source": [
        "and Payment Method Type..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pN-QLt0WCi1t"
      },
      "outputs": [],
      "source": [
        "\n",
        "payment_method_split = dataset[[ \"customerID\", \"PaymentMethod\"]]\n",
        "sectors = payment_method_split  .groupby (\"PaymentMethod\")\n",
        "payment_method_split  = pd.DataFrame(sectors[\"customerID\"].count())\n",
        "payment_method_split.rename(columns={'customerID':'No. of customers'}, inplace=True)\n",
        "\n",
        "\n",
        "ax =  payment_method_split [[\"No. of customers\"]].plot.bar(title = 'Customers by Payment Method', legend =True, table = False, grid = False,  subplots = False,  figsize =(15, 10), color ='#ec838a', fontsize = 15, stacked=False)\n",
        "\n",
        "plt.ylabel('No. of Customers\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
        "plt.xlabel('\\n Contract Type',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
        "plt.title('Customers by Payment Method \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"22\", fontfamily = \"sans-serif\")\n",
        "plt.legend(loc='upper right', fontsize = \"medium\")\n",
        "plt.xticks(rotation=0, horizontalalignment=\"center\")\n",
        "plt.yticks(rotation=0, horizontalalignment=\"right\")\n",
        "\n",
        "x_labels = np.array(payment_method_split [[\"No. of customers\"]])\n",
        "\n",
        "def add_value_labels(ax, spacing=5):   \n",
        "    for rect in ax.patches:      \n",
        "        y_value = rect.get_height()\n",
        "        x_value = rect.get_x() + rect.get_width() / 2       \n",
        "        space = spacing        \n",
        "        va = 'bottom'      \n",
        "        if y_value < 0:           \n",
        "            space *= -1            \n",
        "            va = 'top'       \n",
        "        label = \"{:.0f}\".format(y_value)      \n",
        "        ax.annotate(\n",
        "            label,                      \n",
        "            (x_value, y_value),         \n",
        "            xytext=(0, space),          \n",
        "            textcoords=\"offset points\", \n",
        "            ha='center',                \n",
        "            va=va)                                                             \n",
        "add_value_labels(ax)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJJ-AjPvCi1u"
      },
      "source": [
        "### Target variable comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0xeFpU-Ci1u"
      },
      "source": [
        "#### Overall Churn Rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsovMkC6Ci1u"
      },
      "outputs": [],
      "source": [
        "import matplotlib.ticker as mtick\n",
        "churn_rate = dataset[[\"Churn\", \"customerID\"]]\n",
        "churn_rate [\"churn_label\"] = pd.Series(np.where((churn_rate[\"Churn\"] == 0), \"No\", \"Yes\"))\n",
        "sectors = churn_rate .groupby (\"churn_label\")\n",
        "churn_rate = pd.DataFrame(sectors[\"customerID\"].count())\n",
        "churn_rate [\"Churn Rate\"] = (churn_rate [\"customerID\"] / sum(churn_rate [\"customerID\"]) )*100\n",
        "ax =  churn_rate[[\"Churn Rate\"]].plot.bar(title = 'Overall Churn Rate', legend =True, table = False, grid = False,  subplots = False,  figsize =(12, 7), color = '#ec838a', fontsize = 15, stacked=False, ylim =(0,100))\n",
        "\n",
        "plt.ylabel('Proportion of Customers',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
        "plt.xlabel('Churn',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
        "plt.title('Overall Churn Rate \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"18\", fontfamily = \"sans-serif\")\n",
        "plt.legend(loc='upper right', fontsize = \"medium\")\n",
        "plt.xticks(rotation=0, horizontalalignment=\"center\")\n",
        "plt.yticks(rotation=0, horizontalalignment=\"right\")\n",
        "ax.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
        "x_labels = np.array(churn_rate[[\"customerID\"]])\n",
        "\n",
        "def add_value_labels(ax, spacing=5):   \n",
        "    for rect in ax.patches:     \n",
        "        y_value = rect.get_height()\n",
        "        x_value = rect.get_x() + rect.get_width() / 2       \n",
        "        space = spacing\n",
        "        va = 'bottom'        \n",
        "        if y_value < 0:           \n",
        "            space *= -1          \n",
        "            va = 'top'\n",
        "        \n",
        "        label = \"{:.1f}%\".format(y_value)    \n",
        "        ax.annotate(\n",
        "            label,                      \n",
        "            (x_value, y_value),        \n",
        "            xytext=(0, space),         \n",
        "            textcoords=\"offset points\", \n",
        "            ha='center',                \n",
        "            va=va)                                                            \n",
        "add_value_labels(ax)\n",
        "ax.autoscale(enable=False, axis='both', tight=False)  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqIo6DL_Ci1v"
      },
      "source": [
        "#### Churn Rate by Contract Type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "TREKI4btCi1v"
      },
      "outputs": [],
      "source": [
        "import matplotlib.ticker as mtick\n",
        "\n",
        "contract_churn = dataset.groupby(['Contract','Churn']).size().unstack()\n",
        "\n",
        "contract_churn.rename(columns={0:'No', 1:'Yes'}, inplace=True)\n",
        "\n",
        "colors  = ['#ec838a','#9b9c9a']\n",
        "\n",
        "ax = (contract_churn.T*100.0 / contract_churn.T.sum()).T.plot(kind='bar',\n",
        "                                                                width = 0.3,\n",
        "                                                                stacked = True,\n",
        "                                                                rot = 0, \n",
        "                                                                figsize = (12,7),\n",
        "                                                                color = colors)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plt.ylabel('Proportion of Customers\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
        "plt.xlabel('Contract Type\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
        "plt.title('Churn Rate by Contract type \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"18\", fontfamily = \"sans-serif\")\n",
        "plt.legend(loc='upper right', fontsize = \"medium\")\n",
        "plt.xticks(rotation=0, horizontalalignment=\"center\")\n",
        "plt.yticks(rotation=0, horizontalalignment=\"right\")\n",
        "ax.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
        "for p in ax.patches:\n",
        "    width, height = p.get_width(), p.get_height()\n",
        "    x, y = p.get_xy() \n",
        "    ax.text(x+width/2, \n",
        "            y+height/2, \n",
        "            '{:.1f}%'.format(height), \n",
        "            horizontalalignment='center', \n",
        "            verticalalignment='center')\n",
        "ax.autoscale(enable=False, axis='both', tight=False)   \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "lots more churners on month-to-month contracts"
      ],
      "metadata": {
        "id": "rOUcfcVP-vXP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tx9LnhstCi1w"
      },
      "source": [
        "#### Churn Rate by Payment Method Type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlykH0TkCi1w"
      },
      "outputs": [],
      "source": [
        "import matplotlib.ticker as mtick\n",
        "\n",
        "contract_churn = dataset.groupby(['Contract','PaymentMethod']).size().unstack()\n",
        "\n",
        "contract_churn.rename(columns={0:'No', 1:'Yes'}, inplace=True)\n",
        "\n",
        "colors  = ['#ec838a','#9b9c9a', '#f3babc' , '#4d4f4c']\n",
        "\n",
        "ax = (contract_churn.T*100.0 / contract_churn.T.sum()).T.plot(kind='bar',\n",
        "                                                                width = 0.3,\n",
        "                                                                stacked = True,\n",
        "                                                                rot = 0, \n",
        "                                                                figsize = (12,7),\n",
        "                                                                color = colors)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plt.ylabel('Proportion of Customers\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
        "plt.xlabel('Contract Type\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
        "plt.title('Churn Rate by Payment Method \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"18\", fontfamily = \"sans-serif\")\n",
        "plt.legend(loc='upper right', fontsize = \"medium\")\n",
        "plt.xticks(rotation=0, horizontalalignment=\"center\")\n",
        "plt.yticks(rotation=0, horizontalalignment=\"right\")\n",
        "ax.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
        "for p in ax.patches:\n",
        "    width, height = p.get_width(), p.get_height()\n",
        "    x, y = p.get_xy() \n",
        "    ax.text(x+width/2, \n",
        "            y+height/2, \n",
        "            '{:.1f}%'.format(height), \n",
        "            horizontalalignment='center', \n",
        "            verticalalignment='center')\n",
        "ax.autoscale(enable=False, axis='both', tight=False) "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "and lots of churners pay be electronic check"
      ],
      "metadata": {
        "id": "kZ1IZHcd-3l9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Engineering"
      ],
      "metadata": {
        "id": "xWybkEEMBFFP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHUPyoRdCi1w"
      },
      "source": [
        "### Correlation with Target variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ar7S63XXCi1w"
      },
      "outputs": [],
      "source": [
        "# Find positive and negative correlations with the Response Variable\n",
        "dataset_features = dataset[['SeniorCitizen', 'Partner', 'Dependents',\n",
        "       'tenure', 'PhoneService', 'PaperlessBilling',\n",
        "        'MonthlyCharges', 'TotalCharges']]\n",
        "\n",
        "correlations = dataset_features.corrwith(dataset.Churn)\n",
        "correlations = correlations[correlations!=1]\n",
        "positive_correlations = correlations[correlations >0].sort_values(ascending = False)\n",
        "negative_correlations = correlations[correlations<0].sort_values(ascending = False)\n",
        "\n",
        "print('Most Positive Correlations: \\n', positive_correlations)\n",
        "print('\\nMost Negative Correlations: \\n', negative_correlations)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GQO_DnUCi1x"
      },
      "outputs": [],
      "source": [
        "# plot the correlations\n",
        "correlations = dataset_features.corrwith(dataset.Churn)\n",
        "correlations = correlations[correlations!=1]\n",
        "\n",
        "correlations.plot.bar(\n",
        "        figsize = (10, 7), fontsize = 15, color = '#ec838a',\n",
        "        rot = 45, grid = True)\n",
        "\n",
        "plt.title('Correlation with Churn Rate \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"16\", fontfamily = \"sans-serif\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zezE6QN8Ci1x"
      },
      "source": [
        "#### Feature Correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tl4zbfASCi1x"
      },
      "outputs": [],
      "source": [
        "\n",
        "## Set and compute the Correlation Matrix\n",
        "sn.set(style=\"white\")\n",
        "corr = dataset_features.corr()\n",
        "\n",
        "# Generate a mask for the upper triangle\n",
        "mask = np.zeros_like(corr, dtype=np.bool)\n",
        "mask[np.triu_indices_from(mask)] = True\n",
        "\n",
        "# Set up the matplotlib figure and a diverging colormap\n",
        "f, ax = plt.subplots(figsize=(18, 15))\n",
        "cmap = sn.diverging_palette(220, 10, as_cmap=True)\n",
        "\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "sn.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
        "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qsr1Zx10Ci1x"
      },
      "source": [
        "#### Multicolinearity - VIF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tu7l6ljwCi1x"
      },
      "outputs": [],
      "source": [
        "def calc_vif(X):\n",
        "\n",
        "    # Calculating VIF\n",
        "    vif = pd.DataFrame()\n",
        "    vif[\"variables\"] = X.columns\n",
        "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "    return(vif)\n",
        "\n",
        "dataset_features = dataset[['gender', 'SeniorCitizen', 'Partner', 'Dependents',\n",
        "       'tenure', 'PhoneService', 'PaperlessBilling','MonthlyCharges','TotalCharges']]\n",
        "\n",
        "calc_vif(dataset_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total Charges, Monthly Charges and tenure have VIF > 10 suggesting high correlation with other independent variables (features)"
      ],
      "metadata": {
        "id": "x0Gws4m-AOiO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UojIxmUCi1x"
      },
      "outputs": [],
      "source": [
        "# graphical check for colinearity: \n",
        "dataset_features[['MonthlyCharges', 'TotalCharges']].plot.scatter(figsize = (10, 8), x = 'MonthlyCharges',\n",
        "                                                              y='TotalCharges', color =  '#ec838a')\n",
        "\n",
        "\n",
        "plt.title('Co-linearity of Monthly Charges and Total Charges \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"22\", fontfamily = \"sans-serif\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "lets drop TotalCharges..."
      ],
      "metadata": {
        "id": "-wrXBvYbA1cH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5IIxXDtVCi1x"
      },
      "outputs": [],
      "source": [
        "dataset_features = dataset_features.drop(columns = \"TotalCharges\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# re-validate colinearity:\n",
        "\n",
        "dataset_features = dataset[['gender', 'SeniorCitizen', 'Partner', 'Dependents',\n",
        "       'tenure', 'PhoneService', 'PaperlessBilling','MonthlyCharges']]\n",
        "\n",
        "calc_vif(dataset_features)"
      ],
      "metadata": {
        "id": "c9KJmgI2BU16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ok, looks better, all with VIF < 10"
      ],
      "metadata": {
        "id": "_PHGp3hjCjG6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y86RHjXXCi1y"
      },
      "outputs": [],
      "source": [
        "# apply changes to main dataset:\n",
        "    \n",
        "dataset = dataset.drop(columns = \"TotalCharges\")  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head() # check"
      ],
      "metadata": {
        "id": "sGJmILSNC06x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOUvhhVgCi1y"
      },
      "source": [
        "### Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNbLtzh8Ci1y"
      },
      "outputs": [],
      "source": [
        "# isolate customerID first\n",
        "    \n",
        "identity = dataset[\"customerID\"]\n",
        "\n",
        "final_df = dataset.drop(columns=\"customerID\")\n",
        "\n",
        "# convert rest of categorical variables into dummy variables\n",
        "\n",
        "final_df = pd.get_dummies(final_df)\n",
        "\n",
        "# rejoin userid to dataset (column concatenation)\n",
        "\n",
        "final_df = pd.concat([final_df, identity], axis = 1)\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.head()"
      ],
      "metadata": {
        "id": "q7_wuYktDo3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWMeF6l4Ci1y"
      },
      "source": [
        "### Data Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuwsUVdvCi1y"
      },
      "outputs": [],
      "source": [
        "# target / response variable: \n",
        "response = final_df[\"Churn\"]\n",
        "\n",
        "final_df = final_df.drop(columns=\"Churn\") # features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWeokw_jCi1y"
      },
      "outputs": [],
      "source": [
        "# training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(final_df, response,\n",
        "                                                    stratify=response, \n",
        "                                                    test_size = 0.2, #use 0.9 if data is huge.\n",
        "                                                    random_state = 0)\n",
        "\n",
        "# to resolve any class imbalance - use stratify parameter\n",
        "\n",
        "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
        "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
        "print(\"Number transactions X_test dataset: \", X_test.shape)\n",
        "print(\"Number transactions y_test dataset: \", y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTOSVTHWCi1y"
      },
      "outputs": [],
      "source": [
        "# remove identifiers\n",
        "train_identity = X_train['customerID']\n",
        "X_train = X_train.drop(columns = ['customerID'])\n",
        "\n",
        "test_identity = X_test['customerID']\n",
        "X_test = X_test.drop(columns = ['customerID'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R51DoifRCi1z"
      },
      "source": [
        "### Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdYsx_NQCi1z"
      },
      "outputs": [],
      "source": [
        "sc_X = StandardScaler()\n",
        "X_train2 = pd.DataFrame(sc_X.fit_transform(X_train))\n",
        "X_train2.columns = X_train.columns.values\n",
        "X_train2.index = X_train.index.values\n",
        "X_train = X_train2\n",
        "\n",
        "X_test2 = pd.DataFrame(sc_X.transform(X_test))\n",
        "X_test2.columns = X_test.columns.values\n",
        "X_test2.index = X_test.index.values\n",
        "X_test = X_test2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLNU5gsoCi1z"
      },
      "source": [
        "\n",
        "## Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6_rtXvsCi1z"
      },
      "source": [
        "### Baseline Parallel Run"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NB below parallel run may take up to 5 minutes to run"
      ],
      "metadata": {
        "id": "XeyL_H6PFmLG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Czn9upUmCi1z"
      },
      "outputs": [],
      "source": [
        "# using Accuracy and ROC AUC Mean Metrics\n",
        "\n",
        "\n",
        "models = []\n",
        "\n",
        "models.append(('Logistic Regression', LogisticRegression(solver='liblinear', random_state = 0,\n",
        "                                                         class_weight='balanced')))\n",
        "models.append(('SVC', SVC(kernel = 'linear', random_state = 0)))\n",
        "models.append(('Kernel SVM', SVC(kernel = 'rbf', random_state = 0)))\n",
        "models.append(('KNN', KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)))\n",
        "models.append(('Gaussian NB', GaussianNB()))\n",
        "models.append(('Decision Tree Classifier',\n",
        "               DecisionTreeClassifier(criterion = 'entropy', random_state = 0)))\n",
        "models.append(('Random Forest', RandomForestClassifier(\n",
        "    n_estimators=100, criterion = 'entropy', random_state = 0)))\n",
        "\n",
        "\n",
        "\n",
        "#Evaluating Model Results: \n",
        "\n",
        "acc_results = []\n",
        "auc_results = []\n",
        "names = []\n",
        "# set table to table to populate with performance results\n",
        "col = ['Algorithm', 'ROC AUC Mean', 'ROC AUC STD', \n",
        "       'Accuracy Mean', 'Accuracy STD']\n",
        "\n",
        "model_results = pd.DataFrame(columns=col)\n",
        "i = 0\n",
        "# evaluate each model using k-fold cross-validation\n",
        "for name, model in models:\n",
        "    kfold = model_selection.KFold(\n",
        "        n_splits=10, random_state=0, shuffle = True)  # 10-fold cross-validation\n",
        "\n",
        "    cv_acc_results = model_selection.cross_val_score(  # accuracy scoring\n",
        "        model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
        "\n",
        "    cv_auc_results = model_selection.cross_val_score(  # roc_auc scoring\n",
        "        model, X_train, y_train, cv=kfold, scoring='roc_auc')\n",
        "\n",
        "    acc_results.append(cv_acc_results)\n",
        "    auc_results.append(cv_auc_results)\n",
        "    names.append(name)\n",
        "    model_results.loc[i] = [name,\n",
        "                         round(cv_auc_results.mean()*100, 2),\n",
        "                         round(cv_auc_results.std()*100, 2),\n",
        "                         round(cv_acc_results.mean()*100, 2),\n",
        "                         round(cv_acc_results.std()*100, 2)\n",
        "                         ]\n",
        "    i += 1\n",
        "    \n",
        "model_results.sort_values(by=['ROC AUC Mean'], ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot4Mv9XVCi1z"
      },
      "source": [
        "### Visualise Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZzVT2_yCi1z"
      },
      "outputs": [],
      "source": [
        "# acuracy mean:\n",
        "    \n",
        "fig = plt.figure(figsize=(15, 7))\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(acc_results)\n",
        "ax.set_xticklabels(names)\n",
        "\n",
        "plt.title('Accuracy Score Comparison \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"22\", fontfamily = \"sans-serif\")\n",
        "plt.xticks(rotation=0, horizontalalignment=\"center\")\n",
        "plt.yticks(rotation=0, horizontalalignment=\"right\")\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrO8EUWdCi10"
      },
      "outputs": [],
      "source": [
        "# AUC\n",
        "\n",
        "fig = plt.figure(figsize=(15, 7))\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(auc_results)\n",
        "ax.set_xticklabels(names)\n",
        "\n",
        "plt.title('ROC AUC Comparison \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"22\", fontfamily = \"sans-serif\")\n",
        "\n",
        "plt.xticks(rotation=0, horizontalalignment=\"center\")\n",
        "plt.yticks(rotation=0, horizontalalignment=\"right\")\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DY5HmLoCCi10"
      },
      "outputs": [],
      "source": [
        "\n",
        "#------------------------------------------------------------------------------------------\n",
        "#Compare Baseline Classification Algorithms - Second Iteration\n",
        "#Using Accuracy, Precision, Recall, F1 and F2 Score Metrics\n",
        "#-------------------------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Afp3MwQcCi10"
      },
      "source": [
        "### Parameter search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSbTJz0VCi10"
      },
      "outputs": [],
      "source": [
        "# optimal number of K neighbors for KNN \n",
        "\n",
        "score_array = []\n",
        "for each in range(1,25):\n",
        "    knn_loop = KNeighborsClassifier(n_neighbors = each) #set K neighbor as 3\n",
        "    knn_loop.fit(X_train,y_train)\n",
        "    score_array.append(knn_loop.score(X_test,y_test))\n",
        "\n",
        "fig = plt.figure(figsize=(15, 7))\n",
        "plt.plot(range(1,25),score_array, color = '#ec838a')\n",
        "\n",
        "\n",
        "plt.ylabel('Range\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
        "plt.xlabel('Score\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
        "plt.title('Optimal Number of K Neighbors \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"18\", fontfamily = \"sans-serif\")\n",
        "#plt.legend(loc='top right', fontsize = \"medium\")\n",
        "plt.xticks(rotation=0, horizontalalignment=\"center\")\n",
        "plt.yticks(rotation=0, horizontalalignment=\"right\")\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "so we will say optimal number of K neighbours is 22"
      ],
      "metadata": {
        "id": "pSKYSTGXGwZK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m97jWLhyCi10"
      },
      "outputs": [],
      "source": [
        "# optimal number of trees for random forest\n",
        " \n",
        "score_array = []\n",
        "for each in range(1,100):\n",
        "    rf_loop = RandomForestClassifier(n_estimators = each, random_state = 1) \n",
        "    rf_loop.fit(X_train,y_train)\n",
        "    score_array.append(rf_loop.score(X_test,y_test))\n",
        " \n",
        "fig = plt.figure(figsize=(15, 7))\n",
        "plt.plot(range(1,100),score_array, color = '#ec838a')\n",
        "\n",
        "\n",
        "plt.ylabel('Score\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
        "plt.xlabel('No. of Trees\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
        "plt.title('Optimal Number of Trees for Random Forest Model \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"18\", fontfamily = \"sans-serif\")\n",
        "#plt.legend(loc='top right', fontsize = \"medium\")\n",
        "plt.xticks(rotation=0, horizontalalignment=\"center\")\n",
        "plt.yticks(rotation=0, horizontalalignment=\"right\")\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "lets say 72 decision trees is optimal (i.e. no. of trees which yields the highest score)"
      ],
      "metadata": {
        "id": "FxgxF7bZHfnp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYvQAmZfCi10"
      },
      "source": [
        "### 2nd Iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svFG7ZLBCi10"
      },
      "outputs": [],
      "source": [
        "# Fitting Logistic Regression to the Training set\n",
        "\n",
        "classifier = LogisticRegression(random_state = 0)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# evaluate results\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred )\n",
        "prec = precision_score(y_test, y_pred )\n",
        "rec = recall_score(y_test, y_pred )\n",
        "f1 = f1_score(y_test, y_pred )\n",
        "f2 = fbeta_score(y_test, y_pred, beta=2.0)\n",
        "\n",
        "results = pd.DataFrame([['Logistic Regression', acc, prec, rec, f1, f2]],\n",
        "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'F2 Score'])\n",
        "\n",
        "results = results.sort_values([\"Precision\", \n",
        "\"Recall\", \"F2 Score\"], ascending = False)\n",
        "print (results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9khi_BPCi11"
      },
      "outputs": [],
      "source": [
        "# Fitting linear SVM (SVC class):\n",
        "\n",
        "classifier = SVC(kernel = 'linear', random_state = 0)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# test set predictions\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# evaluate results\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred )\n",
        "prec = precision_score(y_test, y_pred )\n",
        "rec = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred )\n",
        "f2 = fbeta_score(y_test, y_pred, beta=2.0)\n",
        "\n",
        "model_results = pd.DataFrame([['SVM (Linear)', acc, prec, rec, f1, f2]],\n",
        "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'F2 Score'])\n",
        "\n",
        "results = results.append(model_results, ignore_index = True)\n",
        "\n",
        "results = results.sort_values([\"Precision\", \n",
        "\"Recall\", \"F2 Score\"], ascending = False)\n",
        "print (results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7iri88OCi11"
      },
      "outputs": [],
      "source": [
        "# Fitting kernel SVM to the training set\n",
        "\n",
        "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# predicting the Test set results \n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# evaluate results\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred )\n",
        "prec = precision_score(y_test, y_pred )\n",
        "rec = recall_score(y_test, y_pred )\n",
        "f1 = f1_score(y_test, y_pred )\n",
        "f2 = fbeta_score(y_test, y_pred, beta=2.0)\n",
        "\n",
        "model_results = pd.DataFrame([['Kernel SVM', acc, prec, rec, f1, f2]],\n",
        "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'F2 Score'])\n",
        "\n",
        "results = results.append(model_results, ignore_index = True)\n",
        "\n",
        "results = results.sort_values([\"Precision\", \n",
        "\"Recall\", \"F2 Score\"], ascending = False)\n",
        "print (results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxzK-YLzCi11"
      },
      "outputs": [],
      "source": [
        "# Fitting KNN to the Training set\n",
        "\n",
        "classifier = KNeighborsClassifier(n_neighbors = 22, metric = 'minkowski', p = 2)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# predicting the Test set results \n",
        "y_pred  = classifier.predict(X_test)\n",
        "\n",
        "# evaluate results\n",
        "acc = accuracy_score(y_test, y_pred )\n",
        "prec = precision_score(y_test, y_pred )\n",
        "rec = recall_score(y_test, y_pred )\n",
        "f1 = f1_score(y_test, y_pred )\n",
        "f2 = fbeta_score(y_test, y_pred, beta=2.0)\n",
        "\n",
        "model_results = pd.DataFrame([['K-Nearest Neighbours', acc, prec, rec, f1, f2]],\n",
        "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'F2 Score'])\n",
        "\n",
        "results = results.append(model_results, ignore_index = True)\n",
        "\n",
        "results = results.sort_values([\"Precision\", \n",
        "\"Recall\", \"F2 Score\"], ascending = False)\n",
        "print (results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GccmnfcCi11"
      },
      "outputs": [],
      "source": [
        "# Naive Bayes\n",
        "    \n",
        "classifier = GaussianNB()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# predicting the Test set results \n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# evaluate results\n",
        "acc = accuracy_score(y_test, y_pred )\n",
        "prec = precision_score(y_test, y_pred )\n",
        "rec = recall_score(y_test, y_pred )\n",
        "f1 = f1_score(y_test, y_pred )\n",
        "f2 = fbeta_score(y_test, y_pred, beta=2.0)\n",
        "\n",
        "model_results = pd.DataFrame([['Naive Bayes', acc, prec, rec, f1, f2]],\n",
        "                columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'F2 Score'])\n",
        "\n",
        "results = results.append(model_results, ignore_index = True)\n",
        "\n",
        "esults = results.sort_values([\"Precision\", \n",
        "\"Recall\", \"F2 Score\"], ascending = False)\n",
        "print (results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBBe4pEjCi12"
      },
      "outputs": [],
      "source": [
        "# Decision Tree\n",
        "\n",
        "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# predicting the Test set results \n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# evaluate results\n",
        "acc = accuracy_score(y_test, y_pred )\n",
        "prec = precision_score(y_test, y_pred )\n",
        "rec = recall_score(y_test, y_pred )\n",
        "f1 = f1_score(y_test, y_pred )\n",
        "f2 = fbeta_score(y_test, y_pred, beta=2.0)\n",
        "\n",
        "model_results = pd.DataFrame([['Decision Tree', acc, prec, rec, f1, f2]],\n",
        "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'F2 Score'])\n",
        "\n",
        "results = results.append(model_results, ignore_index = True)\n",
        "\n",
        "results = results.sort_values([\"Precision\", \n",
        "\"Recall\", \"F2 Score\"], ascending = False)\n",
        "print (results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B93jOItuCi12"
      },
      "outputs": [],
      "source": [
        "# Random Forest\n",
        "    \n",
        "classifier = RandomForestClassifier(n_estimators = 72, criterion = 'entropy', random_state = 0)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "\n",
        "# predicting the Test set results \n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# evaluate results\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
        "acc = accuracy_score(y_test, y_pred )\n",
        "prec = precision_score(y_test, y_pred )\n",
        "rec = recall_score(y_test, y_pred )\n",
        "f1 = f1_score(y_test, y_pred )\n",
        "f2 = fbeta_score(y_test, y_pred, beta=2.0)\n",
        "\n",
        "model_results = pd.DataFrame([['Random Forest', acc, prec, rec, f1, f2]],\n",
        "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'F2 Score'])\n",
        "\n",
        "results = results.append(model_results, ignore_index = True)\n",
        "\n",
        "results = results.sort_values([\"Precision\", \n",
        "\"Recall\", \"F2 Score\"], ascending = False)\n",
        "print (results)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we will go with logistic regression as the best model across the board..."
      ],
      "metadata": {
        "id": "Jj9eutoXJArO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odH5HT7UCi12"
      },
      "source": [
        "\n",
        "## Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit Logistic Regression Model"
      ],
      "metadata": {
        "id": "BniftqVZJ3lk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYmCVUGYCi12"
      },
      "outputs": [],
      "source": [
        "classifier = LogisticRegression(random_state = 0, penalty = 'l2')\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Predict the Test set results\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "\n",
        "#Evaluate Model Results on Test Set:\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred )\n",
        "prec = precision_score(y_test, y_pred )\n",
        "rec = recall_score(y_test, y_pred )\n",
        "f1 = f1_score(y_test, y_pred )\n",
        "f2 = fbeta_score(y_test, y_pred, beta=2.0)\n",
        "\n",
        "results = pd.DataFrame([['Logistic Regression', acc, prec, rec, f1, f2]],\n",
        "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'F2 Score'])\n",
        "\n",
        "print (results)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### k-Folds Cross Validation"
      ],
      "metadata": {
        "id": "uecCuUHLKCOa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YiQDZPaCi12"
      },
      "outputs": [],
      "source": [
        "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
        "print(\"Logistic Regression Classifier Accuracy: %0.2f (+/- %0.2f)\"  % (accuracies.mean(), accuracies.std() * 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualisation"
      ],
      "metadata": {
        "id": "f-NWYeOPKITS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Confusion Matrix"
      ],
      "metadata": {
        "id": "7elAMRYBKZHv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVk8TImHCi12"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test, y_pred) \n",
        "df_cm = pd.DataFrame(cm, index = (0, 1), columns = (0, 1))\n",
        "plt.figure(figsize = (28,20))\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "sn.set(font_scale=1.4)\n",
        "sn.heatmap(df_cm, annot=True, fmt='g'#,cmap=\"YlGnBu\" \n",
        "           )\n",
        "class_names=[0,1]\n",
        "tick_marks = np.arange(len(class_names))\n",
        "plt.tight_layout()\n",
        "plt.title('Confusion matrix\\n', y=1.1)\n",
        "plt.xticks(tick_marks, class_names)\n",
        "plt.yticks(tick_marks, class_names)\n",
        "ax.xaxis.set_label_position(\"top\")\n",
        "\n",
        "plt.ylabel('Actual label\\n')\n",
        "plt.xlabel('Predicted label\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ROC Curve"
      ],
      "metadata": {
        "id": "QVwHMa73KcPO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klavWEMDCi12"
      },
      "outputs": [],
      "source": [
        "classifier.fit(X_train, y_train) \n",
        "probs = classifier.predict_proba(X_test) \n",
        "probs = probs[:, 1] \n",
        "classifier_roc_auc = accuracy_score(y_test, y_pred )\n",
        "\n",
        "\n",
        "rf_fpr, rf_tpr, rf_thresholds = roc_curve(y_test, classifier.predict_proba(X_test)[:,1])\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# Plot Logistic Regression ROC\n",
        "plt.plot(rf_fpr, rf_tpr, label='Logistic Regression (AUC = %0.2f)' % classifier_roc_auc)\n",
        "# Plot Base Rate ROC\n",
        "plt.plot([0,1], [0,1],label='Random Model')\n",
        "\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "\n",
        "\n",
        "\n",
        "plt.ylabel('True Positive Rate \\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"medium\", fontfamily = \"sans-serif\")\n",
        "plt.xlabel('\\nFalse Positive Rate \\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"medium\", fontfamily = \"sans-serif\")\n",
        "plt.title('ROC Graph \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"22\", fontfamily = \"sans-serif\")\n",
        "plt.legend(loc=\"lower right\", fontsize = \"medium\")\n",
        "plt.xticks(rotation=0, horizontalalignment=\"center\")\n",
        "plt.yticks(rotation=0, horizontalalignment=\"right\")\n",
        "\n",
        "\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntvTWZQjCi13"
      },
      "source": [
        "### Feature Importances"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise – identify the main indicators of churn by looking at feature_importances"
      ],
      "metadata": {
        "id": "9U-JzCZvJIiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hatsD37qJLyP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBg9MIiRCi13"
      },
      "outputs": [],
      "source": [
        "# Analyzing Coefficients\n",
        "feature_importances = pd.concat([pd.DataFrame(final_df.drop(columns = 'customerID').columns, columns = [\"features\"]),\n",
        "           pd.DataFrame(np.transpose(classifier.coef_), columns = [\"coef\"])\n",
        "           ],axis = 1)\n",
        "\n",
        "feature_importances.sort_values(\"coef\", ascending = False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "interesting - Fibre Optic would seem to be a key driver of churn - lets check that:"
      ],
      "metadata": {
        "id": "bm19_VL4Krcf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sense-check"
      ],
      "metadata": {
        "id": "ilKYvGpnHRCJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.ticker as mtick\n",
        "\n",
        "contract_churn = dataset.groupby(['InternetService','Churn']).size().unstack()\n",
        "\n",
        "contract_churn.rename(columns={0:'No', 1:'Yes'}, inplace=True)\n",
        "\n",
        "colors  = ['#ec838a','#9b9c9a']\n",
        "\n",
        "ax = (contract_churn.T*100.0 / contract_churn.T.sum()).T.plot(kind='bar',\n",
        "                                                                width = 0.3,\n",
        "                                                                stacked = True,\n",
        "                                                                rot = 0, \n",
        "                                                                figsize = (12,7),\n",
        "                                                                color = colors)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plt.ylabel('Proportion of Customers\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"medium\", fontfamily = \"sans-serif\")\n",
        "plt.xlabel('InternetService\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"medium\", fontfamily = \"sans-serif\")\n",
        "plt.title('Churn Rate by InternetService \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"18\", fontfamily = \"sans-serif\")\n",
        "plt.legend(loc='upper right', fontsize = \"medium\")\n",
        "plt.xticks(rotation=0, horizontalalignment=\"center\")\n",
        "plt.yticks(rotation=0, horizontalalignment=\"right\")\n",
        "ax.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
        "for p in ax.patches:\n",
        "    width, height = p.get_width(), p.get_height()\n",
        "    x, y = p.get_xy() \n",
        "    ax.text(x+width/2, \n",
        "            y+height/2, \n",
        "            '{:.1f}%'.format(height), \n",
        "            horizontalalignment='center', \n",
        "            verticalalignment='center')\n",
        "ax.autoscale(enable=False, axis='both', tight=False)   "
      ],
      "metadata": {
        "id": "C-2nsfuwK3-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "high number of churners..."
      ],
      "metadata": {
        "id": "KDAlZND9MdZT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OG663gW3Ci13"
      },
      "source": [
        "\n",
        "## Predict Future Churners"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise – carry out future predictions using the trained model"
      ],
      "metadata": {
        "id": "1cu8vlzlJT74"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "calculate each customer's propensity to churn...."
      ],
      "metadata": {
        "id": "DBDZ0If-Nqwh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CZaaRIYCi13"
      },
      "outputs": [],
      "source": [
        "final_results = pd.concat([test_identity, y_test], axis = 1).dropna()\n",
        "\n",
        "final_results['predictions'] = y_pred \n",
        "\n",
        "final_results[\"propensity_to_churn(%)\"] = probs \n",
        "\n",
        "final_results[\"propensity_to_churn(%)\"] = final_results[\"propensity_to_churn(%)\"]*100\n",
        "\n",
        "final_results[\"propensity_to_churn(%)\"] = final_results[\"propensity_to_churn(%)\"].round(2)\n",
        "\n",
        "final_results = final_results[['customerID', 'Churn', 'predictions', 'propensity_to_churn(%)']]\n",
        "\n",
        "final_results ['Ranking'] = pd.qcut(final_results['propensity_to_churn(%)'].rank(method = 'first'),10,labels=range(10,0,-1))\n",
        "\n",
        "print (final_results)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "4c9960f903948092c111fd1da4ed0a7aecc4afac3cee1c1d5130c55e4ff8067f"
      }
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}