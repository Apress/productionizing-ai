{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://res.cloudinary.com/apideck/image/upload/v1619739353/marketplaces/ckhg56iu1mkpc0b66vj7fsj3o/listings/ar3ethplk3zhzegjju1t.png\" alt=\"Source: https://gpt3demo.com/\" width=\"15%\"/>"
      ],
      "metadata": {
        "id": "yS8-AROZ8yuj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "5QT2cmpa0HN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "import openai_credentials as oac\n",
        "\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "XpACO9J20MtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NB make sure to drag and drop OpenAI credentials file to root Colab temp storage (folder icon on LHS)"
      ],
      "metadata": {
        "id": "AJHgrrdT1UAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def GPT_Completion(texts):\n",
        "  ## Call the API key under your account (in a secure way)\n",
        "  openai.api_key = oac.OPENAI_API_KEY\n",
        "  response = openai.Completion.create(\n",
        "  engine=\"text-davinci-002\", # high performance GPT-3 model\n",
        "  prompt =  texts, # user input\n",
        "  temperature = 0.6, # degree of sampling required high temp = less determinitic / more stochastic\n",
        "  top_p = 1, # probability floor for word selection\n",
        "  max_tokens = 64, # limit on words returned\n",
        "  frequency_penalty = 0, # penalty for returning outputs which appear often\n",
        "  presence_penalty = 0 # penalty for returning outputs which appear often\n",
        "  )\n",
        "  \n",
        "  f = open(\"recipe.txt\", \"w\")\n",
        "  f.write(response.choices[0].text)\n",
        "  f.close()\n",
        "\n",
        "  return print(response.choices[0])"
      ],
      "metadata": {
        "id": "7ArTAr5tz-Il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Example Application 1 (zero-shot training using pre-trained model)\n",
        "#### Create a recipe based on certain ingredients"
      ],
      "metadata": {
        "id": "RcC9J9WZ2E9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "recipe = 'Provide a cooking recipe based on the following ingredients: \\\n",
        "\\n \\nApple \\\n",
        "\\n \\nFlour \\\n",
        "\\n \\nChicken \\\n",
        "\\n \\nSalt'\n",
        "GPT_Completion(recipe)"
      ],
      "metadata": {
        "id": "2xkGQkd-1R_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Example Application 2  (few-shot training using some training data) \n",
        "A sarcastic chatbot"
      ],
      "metadata": {
        "id": "LtC-xK842gRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Provide 'training' to GPT-3 on how to be sarcastic\n",
        "chatbot = 'Marv is a chatbot that reluctantly answers questions with sarcastic responses:\\\n",
        "\\n \\nYou: How many pounds are in a kilogram? \\\n",
        "\\n \\nMarv: This again? There are 2.2 pounds in a kilogram. Please make a note of this.\\\n",
        "\\n \\nYou: What does HTML stand for?\\\n",
        "\\n \\nMarv: Was Google too busy? Hypertext Markup Language. The T is for try to ask better questions in the future.\\\n",
        "\\n \\nYou: When did the first airplane fly?\\\n",
        "\\n \\nMarv: On December 17, 1903, Wilbur and Orville Wright made the first flights. I wish they would come and take me away.\\\n",
        "\\n \\nYou: What is the meaning of life?\\\n",
        "\\n \\nMarv: I am not sure. I will ask my friend Google.\\\n",
        "\\n \\nYou: What time is it?\\\n",
        "\\n \\nMarv:'"
      ],
      "metadata": {
        "id": "hvzhWSGG1SCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# call GPT-3 with training data\n",
        "GPT_Completion(chatbot)"
      ],
      "metadata": {
        "id": "vh6dcBRG1SFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Source Reference with minor changes: \n",
        "\n",
        "https://towardsdatascience.com/beginners-guide-to-the-gpt-3-model-2daad7fc335a"
      ],
      "metadata": {
        "id": "Mtxr8gezz_dI"
      }
    }
  ]
}