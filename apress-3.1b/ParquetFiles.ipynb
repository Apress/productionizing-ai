{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QY-Zw03BqZfU"
      },
      "outputs": [],
      "source": [
        "# Libraries\n",
        "\n",
        "import pandas as pd\n",
        "import pyarrow as pa # Apache Arrow open source project for handling pandas DataFrame to Parquet conversions\n",
        "import pyarrow.parquet as pq\n",
        "import platform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIR7LtlsqzCC"
      },
      "outputs": [],
      "source": [
        "# check versions\n",
        "\n",
        "print('Python: ', platform.python_version())\n",
        "print('pandas: ', pd.__version__)\n",
        "print('pyarrow: ', pa.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wn7nuKMRrRUn"
      },
      "outputs": [],
      "source": [
        "#Upload file\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "  \n",
        "#Assign uploaded file to pandas\n",
        "social_index = pd.read_csv(fn, index_col = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMUfKhWwrRdq"
      },
      "outputs": [],
      "source": [
        "# EDA\n",
        "\n",
        "social_index.info(verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rNVe5IXrRgh"
      },
      "outputs": [],
      "source": [
        "social_index.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCYB4iV7rRjp"
      },
      "outputs": [],
      "source": [
        "# mount Google Drive to save the Parquet files\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLIUvSQUvx_T"
      },
      "outputs": [],
      "source": [
        "# convert Pandas DataFrame to Arrows table\n",
        "social_index_table = pa.Table.from_pandas(social_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jg5OyX8VvyEv"
      },
      "outputs": [],
      "source": [
        "# Save Arrow table to parquet - compresses to 75 MB\n",
        "# using default SNAPPY compression\n",
        "\n",
        "pq.write_table(social_index_table, '/content/gdrive/My Drive/Colab Notebooks/US_CDC.parquet', compression='SNAPPY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sN0PxnmvyIY"
      },
      "outputs": [],
      "source": [
        "# read Parquet file back\n",
        "social_index_parquet = pd.read_parquet('/content/gdrive/My Drive/Colab Notebooks/US_CDC.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-diQ5_9vyLP"
      },
      "outputs": [],
      "source": [
        "# validate parquet file by repeating EDA\n",
        "social_index_parquet.info(verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qPRRS20vyON"
      },
      "outputs": [],
      "source": [
        "social_index_parquet.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJhlU9eKxPcM"
      },
      "source": [
        "Open Parquet file in Microsoft Power BI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeT2xtWGwpL0"
      },
      "outputs": [],
      "source": [
        "# download Parquet file from Google Drive\n",
        "# Get data > Moreâ€¦ > \"File\" > \"Parquet\" > point to url of downloaded parquet file\n",
        "# on Google Drive\n",
        "\n",
        "# see reference below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuNybVV0qeVO"
      },
      "source": [
        "Reference: https://sungkim11.medium.com/create-dataset-using-apache-parquet-3701ec3784a9"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}