{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ecedb353",
      "metadata": {
        "id": "ecedb353"
      },
      "source": [
        "Goal: use autoencoders to reduce image noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78079105",
      "metadata": {
        "id": "78079105"
      },
      "outputs": [],
      "source": [
        "# Exercise - embed the image in your notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b5ed44e",
      "metadata": {
        "id": "1b5ed44e"
      },
      "source": [
        "<img src=\"https://miro.medium.com/max/750/1*sahNK4wy4teFA0r6tJJwKQ.png\n",
        "\" alt=\"Stock Price Demo\" width=\"300\" height=200/>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0f496ba",
      "metadata": {
        "id": "f0f496ba"
      },
      "source": [
        "#### Import data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bdd0c4b",
      "metadata": {
        "id": "1bdd0c4b"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist # fashion MNIST data built\n",
        "#into tensorflow\n",
        "\n",
        "# We don't need y_train and y_test\n",
        "(x_train, _), (x_test, _) = fashion_mnist.load_data()\n",
        "\n",
        "print('Max value in the x_train is', x_train[0].max())\n",
        "print('Min value in the x_train is', x_train[0].min())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b49f8faa",
      "metadata": {
        "id": "b49f8faa"
      },
      "source": [
        "#### EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89860c03",
      "metadata": {
        "id": "89860c03"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axs = plt.subplots(5, 10) \n",
        "fig.tight_layout(pad=-1)\n",
        "plt.gray()\n",
        "a = 0 \n",
        "for i in range(5): \n",
        "  for j in range(10): \n",
        "    axs[i, j].imshow(tf.squeeze(x_test[a])) # visualise MNIST images\n",
        "    axs[i, j].xaxis.set_visible(False) \n",
        "    axs[i, j].yaxis.set_visible(False) \n",
        "    a = a + 1 "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf00bbfd",
      "metadata": {
        "id": "cf00bbfd"
      },
      "source": [
        "#### Normalize the Image Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "006a9353",
      "metadata": {
        "id": "006a9353"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee38f019",
      "metadata": {
        "id": "ee38f019"
      },
      "outputs": [],
      "source": [
        "# check the shape of our data\n",
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c792356c",
      "metadata": {
        "id": "c792356c"
      },
      "outputs": [],
      "source": [
        "# we need to add an extra \"dimension\" to turn our image data into a tensor\n",
        "x_train = x_train.reshape(x_train.shape[0],x_train.shape[1],x_train.shape[2],1)\n",
        "x_test = x_test.reshape(x_test.shape[0],x_test.shape[1],x_test.shape[2],1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e50ab667",
      "metadata": {
        "id": "e50ab667"
      },
      "outputs": [],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5b8ba69",
      "metadata": {
        "id": "c5b8ba69"
      },
      "outputs": [],
      "source": [
        "x_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75f08b8a",
      "metadata": {
        "id": "75f08b8a"
      },
      "source": [
        "#### Adding Noise to the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73225be6",
      "metadata": {
        "id": "73225be6"
      },
      "outputs": [],
      "source": [
        "noise_factor = 0.4\n",
        "x_train_noisy = x_train + noise_factor * tf.random.normal(shape=x_train.shape) \n",
        "x_test_noisy = x_test + noise_factor * tf.random.normal(shape=x_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "404f23ef",
      "metadata": {
        "id": "404f23ef"
      },
      "outputs": [],
      "source": [
        "# we need to normalize again as we have added noise\n",
        "x_train_noisy = tf.clip_by_value(x_train_noisy, clip_value_min=0., clip_value_max=1.) \n",
        "x_test_noisy = tf.clip_by_value(x_test_noisy, clip_value_min=0., clip_value_max=1.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cb679c2",
      "metadata": {
        "id": "9cb679c2"
      },
      "outputs": [],
      "source": [
        "# check our \"noisy\" images\n",
        "\n",
        "n = 5\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.gray()\n",
        "\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(2, n, i + 1) \n",
        "  plt.title(\"original\", size=20) \n",
        "  plt.imshow(tf.squeeze(x_test[i])) \n",
        "  plt.gray() \n",
        "  bx = plt.subplot(2, n, n+ i + 1) \n",
        "  plt.title(\"original + noise\", size=20) \n",
        "  plt.imshow(tf.squeeze(x_test_noisy[i])) \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fe985ea",
      "metadata": {
        "id": "2fe985ea"
      },
      "source": [
        "#### Building the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c0752dc",
      "metadata": {
        "id": "6c0752dc"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Conv2DTranspose, Conv2D, Input\n",
        "\n",
        "class NoiseReducer(tf.keras.Model): \n",
        "  def __init__(self):\n",
        "\n",
        "    super(NoiseReducer, self).__init__() \n",
        "\n",
        "    self.encoder = tf.keras.Sequential([ \n",
        "      Input(shape=(28, 28, 1)), \n",
        "      Conv2D(16, (3,3), activation='relu', padding='same', strides=2), \n",
        "      Conv2D(8, (3,3), activation='relu', padding='same', strides=2)]) \n",
        "    \n",
        "    self.decoder = tf.keras.Sequential([ \n",
        "      Conv2DTranspose(8, kernel_size=3, strides=2, activation='relu', padding='same'), \n",
        "      Conv2DTranspose(16, kernel_size=3, strides=2, activation='relu', padding='same'), \n",
        "      Conv2D(1, kernel_size=(3,3), activation='sigmoid', padding='same')]) \n",
        "  \n",
        "  def call(self, x): \n",
        "    encoded = self.encoder(x) \n",
        "    decoded = self.decoder(encoded) \n",
        "    return decoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e25a629d",
      "metadata": {
        "id": "e25a629d"
      },
      "outputs": [],
      "source": [
        "autoencoder = NoiseReducer() # sets up our autoencoder as an instance of our\n",
        "# NoiseReducer class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d79bb7bf",
      "metadata": {
        "id": "d79bb7bf"
      },
      "outputs": [],
      "source": [
        "autoencoder.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "944b9fbf",
      "metadata": {
        "id": "944b9fbf"
      },
      "source": [
        "#### Configuring the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "beda29de",
      "metadata": {
        "id": "beda29de"
      },
      "outputs": [],
      "source": [
        "# Exercise - \n",
        "# a) compile the autoencoder\n",
        "# b) fit the model to the \"noisy\" data and\n",
        "    # benchmark against the original data\n",
        "    # use 10 epochs\n",
        "    # shuffle the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48352e84",
      "metadata": {
        "id": "48352e84"
      },
      "outputs": [],
      "source": [
        "autoencoder.compile(optimizer=\"adam\", loss=\"mse\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9378a32",
      "metadata": {
        "collapsed": true,
        "id": "e9378a32"
      },
      "outputs": [],
      "source": [
        "help(autoencoder.compile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90ac4064",
      "metadata": {
        "id": "90ac4064"
      },
      "outputs": [],
      "source": [
        "autoencoder.fit(x_train_noisy,\n",
        "                x_train, \n",
        "                epochs = 10,\n",
        "                shuffle = True,\n",
        "                validation_data=(x_test_noisy,\n",
        "                x_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d978604",
      "metadata": {
        "id": "4d978604"
      },
      "source": [
        "#### Reducing Image Noise with our trained autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6a4a647",
      "metadata": {
        "id": "b6a4a647"
      },
      "outputs": [],
      "source": [
        "encoded_imgs = autoencoder.encoder(x_test_noisy).numpy()\n",
        "decoded_imgs = autoencoder.decoder(encoded_imgs) # reconstrcuted images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "506eb4b4",
      "metadata": {
        "id": "506eb4b4"
      },
      "outputs": [],
      "source": [
        "# plot - how do our reconstructed images look in comparison with our originals ??\n",
        "\n",
        "\n",
        "n = 10 \n",
        "plt.figure(figsize=(20, 7))\n",
        "plt.gray()\n",
        "for i in range(n): \n",
        "  # display original + noise \n",
        "  bx = plt.subplot(3, n, i + 1) \n",
        "  plt.title(\"original + noise\") \n",
        "  plt.imshow(tf.squeeze(x_test_noisy[i])) \n",
        "  ax.get_xaxis().set_visible(False) \n",
        "  ax.get_yaxis().set_visible(False) \n",
        "  \n",
        "  # display reconstruction \n",
        "  cx = plt.subplot(3, n, i + n + 1) \n",
        "  plt.title(\"reconstructed\") \n",
        "  plt.imshow(tf.squeeze(decoded_imgs[i])) \n",
        "  bx.get_xaxis().set_visible(False) \n",
        "  bx.get_yaxis().set_visible(False) \n",
        "  \n",
        "  # display original \n",
        "  ax = plt.subplot(3, n, i + 2*n + 1) \n",
        "  plt.title(\"original\") \n",
        "  plt.imshow(tf.squeeze(x_test[i])) \n",
        "  ax.get_xaxis().set_visible(False) \n",
        "  ax.get_yaxis().set_visible(False) \n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}