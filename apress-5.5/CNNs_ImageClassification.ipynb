{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNs-ImageClassification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guZkm7j2klUg"
      },
      "source": [
        "Goal:\n",
        "\n",
        "build a CNN using Transfer Learning to predict correct classification for a road sign"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vvzNZpxjf4B"
      },
      "source": [
        "#### Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfLd2CETjr9G"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHWFfxwij-tq"
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(1337) # for recreating results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCHSu6rckEZ9"
      },
      "source": [
        "import tensorflow\n",
        "tensorflow.random.set_seed(42)\n",
        "\n",
        "from tensorflow.python.keras.applications import vgg16\n",
        "from tensorflow.python.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.python.keras import layers, models, Model # , optimizers\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score # performance metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mAxsLSZkyuM"
      },
      "source": [
        "#### Kaggle API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CupJR8tq__4a"
      },
      "source": [
        "1. create API key in Kaggle \n",
        "2. open folder on LHS, go up to root folder\n",
        "3. drag and drop kaggle.json into root folder\n",
        "4. run cells below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRbSmHoz_7YA"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/root\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkGBPfezAjDF"
      },
      "source": [
        "!kaggle datasets download -d meowmeowmeowmeowmeow/gtsrb-german-traffic-sign"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37lwOcBjAnwd"
      },
      "source": [
        "!unzip /content/gtsrb-german-traffic-sign.zip -d review"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6O3G3gWPtKBG"
      },
      "source": [
        "#### EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ep5ugtyZtNKJ"
      },
      "source": [
        "##### Connect to training and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShU9_mfVs_cY"
      },
      "source": [
        "train_data_dir = \"/content/review/train\"\n",
        "test_data_dir = \"/content/review/test\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nGxF_eEtJMT"
      },
      "source": [
        "# plot our training data image distribution\n",
        "\n",
        "category_names = sorted(os.listdir(train_data_dir))\n",
        "nb_categories = len(category_names)\n",
        "img_pr_cat = []\n",
        "for category in category_names:\n",
        "    folder = train_data_dir + '/' + category\n",
        "    img_pr_cat.append(len(os.listdir(folder)))\n",
        "sns.barplot(y=category_names, x=img_pr_cat).set_title(\"Number of training images per category:\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Lwa6OFsujhy"
      },
      "source": [
        "we have too many categories above, so we will use a subset for training purposes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTAC4dlrtJZX"
      },
      "source": [
        "# Exercise - check number of images in the training and test set\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yH2_YCOGvpNl"
      },
      "source": [
        "len(os.listdir(test_data_dir)) # no of files in the test directory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZo7Z0VrvyXO"
      },
      "source": [
        "#mapping for 10 specific signs\n",
        "signs = [\"Bikes\",\"Forbidden_for_traffic\", \"Intersection\", \"No_entry\", \"Pedestrians\", \"Right_of_way\", \"Slippery_road\", \"Speed_60\", \"Stop\", \"Yield\"]\n",
        "\n",
        "signNrs = [\"29\",\"15\", \"11\", \"17\", \"27\", \"12\", \"23\", \"3\", \"14\", \"13\"]\n",
        "\n",
        "# 29 \"Bikes\"\n",
        "# 15 Forbidden_for_traffic\n",
        "# 11 Intersection\n",
        "# 17 No_entry\n",
        "# 27 Pedestrians\n",
        "# 12 Right_of_way\n",
        "# 23 Slippery_road\n",
        "# 3 Speed_60\n",
        "# 14 Stop\n",
        "# 13 Yield"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVEgXygOvygw"
      },
      "source": [
        "# do a plot just for 10 categories above\n",
        "\n",
        "category_names = signs\n",
        "nb_categories = len(category_names)\n",
        "img_pr_cat = []\n",
        "for category in signNrs:\n",
        "    folder = train_data_dir + '/' + category\n",
        "    img_pr_cat.append(len(os.listdir(folder)))\n",
        "sns.barplot(y=category_names, x=img_pr_cat).set_title(\"Number of training images per category:\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iajxRWnDwfjK"
      },
      "source": [
        "dataset is TOO imbalanced, so lets just take 200 random images from each of the 10 folders above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqu47sZawvt3"
      },
      "source": [
        "# Exercise - add code to put 200 random images into a new folder structure\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iydt_WQwv4h"
      },
      "source": [
        "# Exercise - have a go at replicating the above for a smaller (100 image) test and \n",
        "# validation folder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjeYJVnk0UMz"
      },
      "source": [
        "testShort = \"/content/review/test-short\"\n",
        "\n",
        "nr_images = 100\n",
        "\n",
        "# error handler to check if folder exists and remove it first before re-running this cell / recreating the folder\n",
        "try:\n",
        "    shutil.rmtree(testShort) # removes directory\n",
        "except:\n",
        "    pass\n",
        "\n",
        "for i in range (0,10):\n",
        "    \n",
        "    dirpath = os.path.join(train_data_dir, signNrs[i])\n",
        "    # NB below is for creating a test folder, first time this is run, would need to do for train, validate and test sets\n",
        "\n",
        "    destDirectory = os.path.join(testShort , signs[i])\n",
        "    \n",
        "    try:\n",
        "        os.makedirs(destDirectory)\n",
        "    except FileExistsError:\n",
        "        # directory already exists\n",
        "        pass\n",
        "    \n",
        "    filenames = random.sample(os.listdir(dirpath), nr_images)\n",
        "    \n",
        "    for fname in filenames:\n",
        "        srcpath = os.path.join(dirpath, fname)\n",
        "        destpath = os.path.join(destDirectory, fname)\n",
        "        shutil.copyfile(srcpath, destpath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dj7okx2M0aBw"
      },
      "source": [
        "valShort = \"/content/review/val-short\"\n",
        "\n",
        "nr_images = 100\n",
        "\n",
        "# add an error handler to check if folder exists and remove it first before re-running this cell / recreating the folder\n",
        "try:\n",
        "    shutil.rmtree(valShort) # removes directory\n",
        "except:\n",
        "    pass\n",
        "\n",
        "for i in range (0,10):\n",
        "    \n",
        "    dirpath = os.path.join(train_data_dir, signNrs[i])\n",
        "    # NB below is for creating a test folder, first time this is run, would need to do for train, validate and test sets\n",
        "\n",
        "    destDirectory = os.path.join(valShort , signs[i])\n",
        "    \n",
        "    try:\n",
        "        os.makedirs(destDirectory)\n",
        "    except FileExistsError:\n",
        "        # directory already exists\n",
        "        pass\n",
        "    \n",
        "    filenames = random.sample(os.listdir(dirpath), nr_images)\n",
        "    \n",
        "    for fname in filenames:\n",
        "        srcpath = os.path.join(dirpath, fname)\n",
        "        destpath = os.path.join(destDirectory, fname)\n",
        "        shutil.copyfile(srcpath, destpath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rN6v8SuI0yO_"
      },
      "source": [
        "##### Check our subset of images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTYIPiTW0jZj"
      },
      "source": [
        "# do a plot just for 10 categories above\n",
        "\n",
        "category_names = signs\n",
        "nb_categories = len(category_names)\n",
        "img_pr_cat = []\n",
        "for category in signs:\n",
        "    folder = trainShort + '/' + category\n",
        "    img_pr_cat.append(len(os.listdir(folder)))\n",
        "sns.barplot(y=category_names, x=img_pr_cat).set_title(\"Number of training images per category:\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnL1VX8t0lBG"
      },
      "source": [
        "#### Model Prep"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUoQ31w61O0p"
      },
      "source": [
        "###### Converting images into numpy arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZ2VN1yr0jck"
      },
      "source": [
        "import cv2 # Computer Vision library for python\n",
        "\n",
        "train_width=[]\n",
        "test_width=[]\n",
        "cv_width=[]\n",
        "count=0\n",
        "\n",
        "for category in category_names: \n",
        "  print(\"train \" + category ) # update user at what stage we are at\n",
        "  folder = trainShort + '/' + category\n",
        "  for image in os.listdir(trainShort + '/' + category):\n",
        "          im = cv2.imread(folder + '/' + image,cv2.IMREAD_GRAYSCALE)\n",
        "          train_width.append(im.shape[1])\n",
        "        \n",
        "\n",
        "  print(\"test \"+ category ) # update user at what stage we are at  \n",
        "  folder = testShort+ '/' + category\n",
        "  for image in os.listdir(testShort + '/' + category):\n",
        "          im = cv2.imread(folder + '/' + image,cv2.IMREAD_GRAYSCALE)\n",
        "          test_width.append(im.shape[1])\n",
        "          \n",
        "  print(\"val \"+ category) # update user at what stage we are at\n",
        "  folder = valShort+ '/' + category \n",
        "  for image in os.listdir(valShort + '/' + category):\n",
        "          im = cv2.imread(folder + '/' + image,cv2.IMREAD_GRAYSCALE)\n",
        "          cv_width.append(im.shape[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgK41qsa0jfq"
      },
      "source": [
        "# check - quick peek at how the image data is converted using Computer Vision\n",
        "cv2.imread(folder + '/' + image,cv2.IMREAD_GRAYSCALE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-kXM19O2GdI"
      },
      "source": [
        "##### Plot image widths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5kcGkIC0jif"
      },
      "source": [
        "# show widths of images in each folder\n",
        "\n",
        "width=(train_width,test_width,cv_width)\n",
        "\n",
        "for x in width:\n",
        "  sns.distplot(x,kde = True)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASsq6E6h3Sbg"
      },
      "source": [
        "##### Check image samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGUI4-ef0jlL"
      },
      "source": [
        "# show one example image from each classification folder\n",
        "\n",
        "for subdir, dirs, files in os.walk(trainShort):\n",
        "    for file in files:\n",
        "        img_file = subdir + '/' + file\n",
        "        image = load_img(img_file)\n",
        "        plt.figure()\n",
        "        plt.title(subdir)\n",
        "        plt.imshow(image)\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hpMZqD-337m"
      },
      "source": [
        "#### Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBt_nGlE0joF"
      },
      "source": [
        "img_height, img_width = 224,224\n",
        "#our convolution \"base\" is the VGG model - we are using it for \"transfer learning\"\n",
        "conv_base = vgg16.VGG16(weights='imagenet', include_top=False, pooling='max', input_shape = (img_width, img_height, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaX8TXGv0jrS"
      },
      "source": [
        "# view the convolutional layers\n",
        "for layer in conv_base.layers:\n",
        "  print(layer, layer.trainable)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KE4u51bwn20"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Dense(nb_categories,activation=\"softmax\"))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQaUFpje0Vdx"
      },
      "source": [
        "##### Generators for reading and processing images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Jc7G8lF0AkP"
      },
      "source": [
        "#Number of images to load at each iteration\n",
        "\n",
        "batch_size = 32\n",
        "# only rescaling\n",
        "train_datagen =  ImageDataGenerator(\n",
        "    rescale=1./255\n",
        ")\n",
        "test_datagen =  ImageDataGenerator(\n",
        "    rescale=1./255\n",
        ")\n",
        "\n",
        "# these are generators for train/test data that will read pictures #found in the defined subfolders of 'data/'\n",
        "print('Total number of images for \"training\":')\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "trainShort,\n",
        "target_size = (img_height, img_width),\n",
        "batch_size = batch_size, \n",
        "class_mode = \"categorical\")\n",
        "\n",
        "print('Total number of images for \"validation\":')\n",
        "val_generator = test_datagen.flow_from_directory(\n",
        "valShort,\n",
        "target_size = (img_height, img_width),\n",
        "batch_size = batch_size,\n",
        "class_mode = \"categorical\",\n",
        "shuffle=False)\n",
        "\n",
        "print('Total number of images for \"testing\":')\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "testShort,\n",
        "target_size = (img_height, img_width),\n",
        "batch_size = batch_size,\n",
        "class_mode = \"categorical\",\n",
        "shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2ziFvAR61bv"
      },
      "source": [
        "##### Compile & Build Model Baseline\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSLtbRp514u3"
      },
      "source": [
        "learning_rate = 5e-5\n",
        "epochs = 10\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"traffic-28jun21.h5\", monitor = 'val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto',save_freq=1)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(learning_rate, clipnorm = 1.), metrics = ['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NSyyGtg2ve6"
      },
      "source": [
        "history = model.fit(train_generator,\n",
        "                    epochs = epochs,\n",
        "                    shuffle=True,\n",
        "                    validation_data=val_generator,\n",
        "                    callbacks=[checkpoint])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "970LR9cpiYx9"
      },
      "source": [
        "##### Evaluating Model Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RC_GcnsRiSPr"
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1,len(acc)+1)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, acc, 'b', label = 'Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.savefig('Accuracy.jpg')\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'b', label = 'Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.savefig('Loss.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAY6v5Hp3-x9"
      },
      "source": [
        "# Exercise - model looks overfit - re-run using a technique to avoid overfitting"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4RJWx3167nk"
      },
      "source": [
        "##### 2nd Run - Early Stopping Criteria"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sx-EE8u76nKP"
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "learning_rate = 5e-5\n",
        "epochs = 10\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(learning_rate, clipnorm = 1.), metrics = ['acc'])\n",
        "\n",
        "es = EarlyStopping(monitor = \"val_loss\", mode=\"min\", verbose = 1)\n",
        "mc = ModelCheckpoint(\"best-model.h5\", monitor = 'val_acc', mode=\"max\", verbose=1, save_best_only=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfAFRj4f6nNs"
      },
      "source": [
        "history = model.fit(train_generator,\n",
        "                    epochs = epochs,\n",
        "                    shuffle=True,\n",
        "                    validation_data=val_generator,\n",
        "                    callbacks=[es,mc]) # early stopping and checkpint handled by callbacks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viNnEtstDF5b"
      },
      "source": [
        "##### 2nd Run - Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FAF1VRN9Pfh"
      },
      "source": [
        "#access our \"best model\" from the last run\n",
        "\n",
        "from keras.models import load_model\n",
        "saved_model = models.load_model(\"best-model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0i1gJbGc_e46"
      },
      "source": [
        "# function to plot the confusion matrix below\n",
        "\n",
        "def plot_confusion_matrix(cm, classes, figname,\n",
        "  normalize=False,\n",
        "  title='Confusion matrix',\n",
        "  cmap=plt.cm.Blues):\n",
        "  \"\"\"\n",
        "  This function prints and plots the confusion matrix.\n",
        "  Normalization can be applied by setting `normalize=True`.\n",
        "  \"\"\"\n",
        "  import itertools\n",
        "  if normalize:\n",
        "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    print(\"Normalized confusion matrix\")\n",
        "  else:\n",
        "    print('Confusion matrix, without normalization')\n",
        "  plt.figure(figsize=(8,8))\n",
        "  plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "  plt.title(title)\n",
        "  #plt.colorbar()\n",
        "  tick_marks = np.arange(len(classes))\n",
        "  plt.xticks(tick_marks, classes, rotation=90)\n",
        "  plt.yticks(tick_marks, classes)\n",
        "  fmt = '.2f' if normalize else 'd'\n",
        "  thresh = cm.max() / 2.\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    plt.text(j, i, format(cm[i, j], fmt),\n",
        "  horizontalalignment=\"center\",\n",
        "  color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "  plt.ylabel('True label')\n",
        "  plt.xlabel('Predicted label')\n",
        "  plt.tight_layout()\n",
        "  plt.savefig(figname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YIfF3Jb9q7B"
      },
      "source": [
        "# Exercise - Confusion Matrix\n",
        "# plot how the model predicted EACH trafic sign against the actual traffic sign classification\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "momD-Pg6B0cx"
      },
      "source": [
        "#### Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQUa6yFrCDym"
      },
      "source": [
        "from keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "# testing a couple of images\n",
        "image1file = test_data_dir+ \"/\" + \"00007.png\" # right of way\n",
        "image2file  = test_data_dir + \"/\" + \"00906.png\" # yield\n",
        "image3file  = test_data_dir + \"/\" + \"00904.png\" # pedestrians\n",
        "image4file  = test_data_dir + \"/\" + \"00288.png\" # no entry"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3LTnivwC-CZ"
      },
      "source": [
        "#images loaded in PIL (Python Imaging Library)\n",
        "img1 = image.load_img(image1file,color_mode='rgb', target_size=(224, 224))\n",
        "display(img1)\n",
        "img2 = image.load_img(image2file,color_mode='rgb', target_size=(224, 224))\n",
        "display(img2)\n",
        "img3 = image.load_img(image3file,color_mode='rgb', target_size=(224, 224))\n",
        "display(img3)\n",
        "img4 = image.load_img(image4file,color_mode='rgb', target_size=(224, 224))\n",
        "display(img4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HnAHFIhD2fU"
      },
      "source": [
        "# convert PIL images to numpy arrays\n",
        "\n",
        "import numpy as np \n",
        "from numpy import array\n",
        "\n",
        "# Converts a PIL Image to 3D Numpy Array\n",
        "image1_array = image.img_to_array(img1) # this adds a 3rd dimension, at the end \"3\" which refers I think to RGB format\n",
        "# basically height and width are both 224 and the size of depth or number of activation maps, channels here, is 3\n",
        "print(image1_array.shape)\n",
        "# Adding the fouth dimension, for number of images\n",
        "image1_array = np.expand_dims(image1_array, axis=0)\n",
        "\n",
        "image2_array = image.img_to_array(img2)\n",
        "image2_array.shape\n",
        "image2_array = np.expand_dims(image2_array, axis=0)\n",
        "\n",
        "image3_array = image.img_to_array(img3)\n",
        "image3_array.shape\n",
        "image3_array = np.expand_dims(image3_array, axis=0)\n",
        "\n",
        "image4_array = image.img_to_array(img4)\n",
        "image4_array.shape\n",
        "image4_array = np.expand_dims(image4_array, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxB6ehibEMt_"
      },
      "source": [
        "# predict classes for our four chosen images\n",
        "\n",
        "print(image1_array.shape)\n",
        "\n",
        "image1_array.shape==(1, 224, 224, 3)\n",
        "\n",
        "#normalize images\n",
        "im1arr = image1_array / 255.0\n",
        "im2arr = image2_array / 255.0\n",
        "im3arr = image3_array / 255.0\n",
        "im4arr = image4_array / 255.0\n",
        "\n",
        "pred1 = saved_model.predict_classes([im1arr])[0]\n",
        "pred2 = saved_model.predict_classes([im2arr])[0]\n",
        "pred3 = saved_model.predict_classes([im3arr])[0]\n",
        "pred4 = saved_model.predict_classes([im4arr])[0]\n",
        "\n",
        "print(pred1,\",\",pred2,\",\",pred3,\",\",pred4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjfGwh7TEfNR"
      },
      "source": [
        "# predicted category names\n",
        "print(category_names[pred1],\",\",category_names[pred2],\",\",category_names[pred3],\",\",category_names[pred4])\n",
        "\n",
        "print_msg1 = str(category_names[pred1]) + \" (probability: \" + str(np.max(saved_model.predict_proba([im1arr])))+ \")\"\n",
        "\n",
        "# predicted sign type\n",
        "str(np.max(saved_model.predict([im1arr])))\n",
        "\n",
        "print(print_msg1)\n",
        "\n",
        "print_msg2 = str(category_names[pred2]) + \" (probability: \" + str(np.max(saved_model.predict_proba([im2arr])))+ \")\"\n",
        "\n",
        "# predicted sign type\n",
        "str(np.max(saved_model.predict([im2arr])))\n",
        "\n",
        "print(print_msg2)\n",
        "\n",
        "print_msg3 = str(category_names[pred3]) + \" (probability: \" + str(np.max(saved_model.predict_proba([im3arr])))+ \")\"\n",
        "\n",
        "# predicted sign type\n",
        "str(np.max(saved_model.predict([im3arr])))\n",
        "\n",
        "print(print_msg3)\n",
        "\n",
        "print_msg4 = str(category_names[pred4]) + \" (probability: \" + str(np.max(saved_model.predict_proba([im4arr])))+ \")\"\n",
        "\n",
        "# predicted sign type\n",
        "str(np.max(saved_model.predict([im4arr])))\n",
        "\n",
        "print(print_msg4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1DNZriVE2cf"
      },
      "source": [
        "# Exercise - see if you go thru the source test folder\n",
        "# a) choose 4 images that are within our 10 categories\n",
        "# b) do some predictions\n",
        "# c) compare with the actual sign type"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}